{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaoloBarba/NN_Homework_1/blob/main/NNDS_2023_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks for Data Science Applications\n",
        "## Homework 1: Saliency maps for interpretability\n",
        "\n",
        "**Name**: *Paolo*\n",
        "\n",
        "**Matricola**: *1885324*\n",
        "\n",
        "> ‚úç Upload the completed notebook **before 10/11/2023 at 23:59** on the Google Classroom page."
      ],
      "metadata": {
        "id": "BwfXT98e5hQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5V6Ph3UT44Xo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To ensure reproducible results (as much as possible)\n",
        "tf.keras.utils.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "GkYGd_WY_2nq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview\n",
        "\n",
        "Neural networks are powerful tools, but they are **black-boxes**, meaning that it is difficult to provide human-understandable explanations on what they are doing. The field of **explanaibility** is concerned with finding algorithms for achieving this. In this homework, you will be guided in implementing some basic explanaibility algorithms (**saliency maps**), which is an instructive way of playing with the TensorFlow autodiff framework.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. The homework is divided into four mandatory exercises (**5 points in total**), and a few optional exercises. Optional exercises are provided if you like the topic and would like to explore more; you are free to ignore them or complete as many as you want. I will not grade them but I might provide feedback for especially nice solutions.\n",
        "2. Completing the homework successfully will remove 1 exercise from the end-of-term homework.\n",
        "3. If your grade does not satisfy you, you are also free to complete the full EoT homework to recover it.\n",
        "3. The grade can be kept for the entire academic year (up to October 2024).\n",
        "\n",
        "**IMPORTANT - read carefully before starting**:\n",
        "\n",
        "> üü® *External material*: if you use any external material or inspiration for the code, reference it *explicitly* in the corresponding cell. For the textual descriptions, copy-paste *is not allowed*. <ins>Not following these two points is an immediate 0 mark</ins>.\n",
        "\n",
        "> üîµ *Grammar*: for the textual descriptions, I will remove points for too many grammatical or textual errors. Please try to be precise and provide nice-to-read descriptions, like if you were writing a report.\n",
        "\n",
        "> üü• *Vectorization and TensorFlow*: the homework must be done _fully in TensorFlow_ and vectorizing the code as much as possible (e.g., do not loop explicitly over the batch dimension).\n",
        "\n",
        "> üü™ *Math*: you can also use LaTeX in Markdown if you need to write equations or if you need generic math notation."
      ],
      "metadata": {
        "id": "BmzKI83R0uYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warmup: Data loading\n",
        "\n",
        "For this homework, you can select any **tabular dataset** that you like, for either classification or regression. A few repositories that you can look at:\n",
        "\n",
        "1. The catalog of [TensorFlow Datasets](https://www.tensorflow.org/datasets/).\n",
        "2. The [Kaggle catalog](https://www.kaggle.com/data). For downloading data from Kaggle on Google Colab, you will need to [load your Kaggle authentication token](https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb).\n",
        "3. The [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php).\n",
        "4. The [ü§ó HuggingFace Datasets](https://huggingface.co/docs/datasets/) repository.\n",
        "\n",
        "You are not bound to these; any open repository is okay. The choice of dataset will not influence the mark."
      ],
      "metadata": {
        "id": "SE7pCfZK2G5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úç **DESCRIPTION OF THE CODE**\n",
        "\n",
        "*Provide a small description of the dataset below (e.g., source, task, bibliographic reference if necessary...), both as text and in the comments of the code.*\n",
        "\n",
        "The dataset originates from StatsBomb and has undergone\n",
        "necessary processing, It comprises records of matches played\n",
        "by Barcelona FC and by the usage of linear algebra I extracted relevant features such as distance, angle ecc...\n",
        "Then I cleaned the datast to be suitable for a neural network architecture.\n",
        "\n",
        " [It is possible to see the data cleaning procedure at the following link $\\href{https://github.com/PaoloBarba/NN_Homework_1/blob/main/Clean_data.ipynb}{\\text{Link to repository}}$\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "fzThDtr4VJ5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Insert any data loading code here. If the data loading part is complex,\n",
        "# consider using a separate .py file that you can attach to the submission.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('shots_for_nn.tsv' , sep = '\\t')\n",
        "X , y = data.drop(['outcome'] , axis = 1).values , data['outcome'].values\n"
      ],
      "metadata": {
        "id": "FpQj4F8n20LI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check the frequency of the target variable in  order to chooce the best\n",
        "# metric to maximize\n",
        "categ = pd.Series(y)\n",
        "value_counts = categ.value_counts()\n",
        "\n",
        "# Create the bar plot\n",
        "plt.bar(value_counts.index, value_counts.values)\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Bar Plot of Outcome varible')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uGlEnttcanSu",
        "outputId": "0a244a1d-717b-4c76-b812-e03478b32def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts / len(y)"
      ],
      "metadata": {
        "id": "AcxN4Y2Avccb",
        "outputId": "aef6ede8-8b8a-4058-bb29-d11726323fa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No_Goal    0.863272\n",
              "Goal       0.136728\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plot it seems that the dataset is unbalance on the target variable 'outcome'. The decision of the metric we want to maximize has to take into account the unbalancness of the target varibale. I will choose the following metric\n",
        "\n",
        "\n",
        "$$\n",
        "\\textbf{Balanced Accuracy} = \\frac{1}{2} \\left( \\frac{TP}{TP+FN} + \\frac{TN}{TN+FP} \\right)$$\n"
      ],
      "metadata": {
        "id": "AH3LaLW-b1N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "# Define a custom metric function for balanced accuracy\n",
        "def balanced_accuracy(y_true, y_pred):\n",
        "    y_true = tf.argmax(y_true, axis=1)\n",
        "    y_pred = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Calculate true positives, true negatives, false positives, and false negatives\n",
        "    true_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 1)), tf.float32))\n",
        "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred, 0)), tf.float32))\n",
        "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred, 1)), tf.float32))\n",
        "    false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 0)), tf.float32))\n",
        "\n",
        "    # Calculate balanced accuracy\n",
        "    sensitivity = true_positives / (true_positives + false_negatives + tf.keras.backend.epsilon())\n",
        "    specificity = true_negatives / (true_negatives + false_positives + tf.keras.backend.epsilon())\n",
        "    balanced_accuracy = (sensitivity + specificity) / 2.0\n",
        "\n",
        "    return balanced_accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "HxCpHA0jhN78"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1: Train a neural network model (1 point)\n",
        "\n",
        "Define, train, and test a neural network for the provided dataset.\n",
        "\n",
        "‚òù You are free to make any modelling choice (e.g., activation function, normalization layers, etc.), provided the result makes sense.\n",
        "\n",
        "‚úÖ **Completion requirement**: print on screen the test accuracy of the network. Additional comments and visualizations are also appreciated."
      ],
      "metadata": {
        "id": "5Myy-Aq33upU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "y_train = encoder.fit_transform(y_train).toarray()\n",
        "y_test = encoder.fit_transform(y_test).toarray()\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(39,), activation='relu'),  # Input layer with 64 units and ReLU activation\n",
        "    Dense(32, activation='relu'),  # Hidden layer with 32 units and ReLU activation\n",
        "    Dense(2, activation='softmax')  # Output layer with 2 units (for binary classification) and softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= [balanced_accuracy])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split = 0.4)\n"
      ],
      "metadata": {
        "id": "_gTJIyBm5WHB",
        "outputId": "9960f2c3-cdf2-42ae-d876-831edd38e98e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "169/169 [==============================] - 2s 7ms/step - loss: 0.5081 - balanced_accuracy: 0.5144 - val_loss: 0.3643 - val_balanced_accuracy: 0.5548\n",
            "Epoch 2/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3768 - balanced_accuracy: 0.5397 - val_loss: 0.4132 - val_balanced_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3563 - balanced_accuracy: 0.5422 - val_loss: 0.3444 - val_balanced_accuracy: 0.5968\n",
            "Epoch 4/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3780 - balanced_accuracy: 0.5559 - val_loss: 0.3532 - val_balanced_accuracy: 0.5421\n",
            "Epoch 5/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3520 - balanced_accuracy: 0.5546 - val_loss: 0.3491 - val_balanced_accuracy: 0.6132\n",
            "Epoch 6/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3585 - balanced_accuracy: 0.5740 - val_loss: 0.3519 - val_balanced_accuracy: 0.5280\n",
            "Epoch 7/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3566 - balanced_accuracy: 0.5775 - val_loss: 0.3359 - val_balanced_accuracy: 0.5857\n",
            "Epoch 8/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3504 - balanced_accuracy: 0.5763 - val_loss: 0.3450 - val_balanced_accuracy: 0.5841\n",
            "Epoch 9/30\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.3505 - balanced_accuracy: 0.5756 - val_loss: 0.3376 - val_balanced_accuracy: 0.5540\n",
            "Epoch 10/30\n",
            "169/169 [==============================] - 2s 9ms/step - loss: 0.3446 - balanced_accuracy: 0.5758 - val_loss: 0.3673 - val_balanced_accuracy: 0.5295\n",
            "Epoch 11/30\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.3441 - balanced_accuracy: 0.5796 - val_loss: 0.3340 - val_balanced_accuracy: 0.5983\n",
            "Epoch 12/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3460 - balanced_accuracy: 0.5905 - val_loss: 0.3402 - val_balanced_accuracy: 0.6088\n",
            "Epoch 13/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3460 - balanced_accuracy: 0.5732 - val_loss: 0.3356 - val_balanced_accuracy: 0.5891\n",
            "Epoch 14/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3385 - balanced_accuracy: 0.5856 - val_loss: 0.3395 - val_balanced_accuracy: 0.6033\n",
            "Epoch 15/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3390 - balanced_accuracy: 0.5729 - val_loss: 0.3346 - val_balanced_accuracy: 0.6107\n",
            "Epoch 16/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3491 - balanced_accuracy: 0.5802 - val_loss: 0.3359 - val_balanced_accuracy: 0.6109\n",
            "Epoch 17/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3428 - balanced_accuracy: 0.5813 - val_loss: 0.3361 - val_balanced_accuracy: 0.5788\n",
            "Epoch 18/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3370 - balanced_accuracy: 0.5751 - val_loss: 0.3422 - val_balanced_accuracy: 0.6245\n",
            "Epoch 19/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3421 - balanced_accuracy: 0.5861 - val_loss: 0.3337 - val_balanced_accuracy: 0.5980\n",
            "Epoch 20/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3428 - balanced_accuracy: 0.5771 - val_loss: 0.3682 - val_balanced_accuracy: 0.5368\n",
            "Epoch 21/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3374 - balanced_accuracy: 0.5845 - val_loss: 0.3482 - val_balanced_accuracy: 0.6152\n",
            "Epoch 22/30\n",
            "169/169 [==============================] - 1s 8ms/step - loss: 0.3486 - balanced_accuracy: 0.5819 - val_loss: 0.3361 - val_balanced_accuracy: 0.6194\n",
            "Epoch 23/30\n",
            "169/169 [==============================] - 1s 8ms/step - loss: 0.3361 - balanced_accuracy: 0.5794 - val_loss: 0.3333 - val_balanced_accuracy: 0.5921\n",
            "Epoch 24/30\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.3359 - balanced_accuracy: 0.5667 - val_loss: 0.3333 - val_balanced_accuracy: 0.6070\n",
            "Epoch 25/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3419 - balanced_accuracy: 0.5798 - val_loss: 0.3365 - val_balanced_accuracy: 0.5794\n",
            "Epoch 26/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3390 - balanced_accuracy: 0.5787 - val_loss: 0.3323 - val_balanced_accuracy: 0.5883\n",
            "Epoch 27/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3404 - balanced_accuracy: 0.5763 - val_loss: 0.3404 - val_balanced_accuracy: 0.5495\n",
            "Epoch 28/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3331 - balanced_accuracy: 0.5763 - val_loss: 0.3315 - val_balanced_accuracy: 0.5870\n",
            "Epoch 29/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3364 - balanced_accuracy: 0.5736 - val_loss: 0.3410 - val_balanced_accuracy: 0.5625\n",
            "Epoch 30/30\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.3384 - balanced_accuracy: 0.5695 - val_loss: 0.3366 - val_balanced_accuracy: 0.6124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d73e83f99f0>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "-7eEz17Ory_J",
        "outputId": "6589d5b2-3fde-43cb-838c-516da2d6fbf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8990, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Add a hidden layer with 16 units and 'relu' activation function\n",
        "model.add(tf.keras.layers.Dense(16, input_dim= ))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "# Add an output layer with 8 units for 8-class classification and 'softmax' activation function\n",
        "model.add(tf.keras.layers.Dense(8))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_combined, y, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "3fL6S45u0yH5",
        "outputId": "63426b25-ee22-48d4-c045-ea264d2ca4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-deb30383eabf>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/Cast defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-29-deb30383eabf>\", line 15, in <cell line: 15>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5727, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 2305, in cast\n\n2 root error(s) found.\n  (0) UNIMPLEMENTED:  Cast string to int64 is not supported\n\t [[{{node sparse_categorical_crossentropy/Cast}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_20114]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ISQ7CfvNirvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "godyFivmXNNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: train the neural network.\n"
      ],
      "metadata": {
        "id": "PgB37IKKWuhj",
        "outputId": "d4447404-3db0-4c5d-f864-989368a265dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-635f7cf1ddce>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: train the neural network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# which does not have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;34mf\"Inputs to a layer should be tensors. Got '{x}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34mf\"(of type {type(x)}) as input for layer '{layer_name}'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'sequential' (type Sequential).\n\nInputs to a layer should be tensors. Got '<_BatchDataset element_spec=({'location_x': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'location_y': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'player': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'bodypart': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'technique': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'first_touch': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'state_of_play': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'inside_18_width': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'inside_18_depth': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'inside_18': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'shot_distance': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'shot_angle': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'bodypart_angle': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'significant_time': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>' (of type <class 'tensorflow.python.data.ops.batch_op._BatchDataset'>) as input for layer 'dense'.\n\nCall arguments received by layer 'sequential' (type Sequential):\n  ‚Ä¢ inputs=<_BatchDataset element_spec=({'location_x': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'location_y': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'player': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'bodypart': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'technique': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'first_touch': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'state_of_play': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'inside_18_width': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'inside_18_depth': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'inside_18': TensorSpec(shape=(None,), dtype=tf.bool, name=None), 'shot_distance': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'shot_angle': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'bodypart_angle': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'significant_time': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>\n  ‚Ä¢ training=None\n  ‚Ä¢ mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: test the neural network and print the result on screen."
      ],
      "metadata": {
        "id": "cJJFyts8Wqez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: Computing a vanilla saliency map (1 points)\n",
        "\n",
        "> Before starting, I suggest you read [1] as a warm-up. This is one of the first papers that tried to apply this kind of techniques to modern neural networks.\n",
        "\n",
        "What do we mean by explainability? Consider the neural network $f(\\cdot)$ you just trained, and a prediction $\\hat{y} = f(x)$ we want to analyze. **Feature attribution** methods try to assign a weight $w_i$ to each input feature $x_i$, to understand which parts of the input have contributed the most to the explanation.\n",
        "\n",
        "The simplest feature attribution technique, called **vanilla saliency map**, simply computes the gradient at that point:\n",
        "\n",
        "$$\n",
        "  S(x) = \\left\\lvert \\frac{\\partial f_c(x)}{\\partial x} \\right\\rvert\n",
        "$$\n",
        "\n",
        "where  $c$ is the index corresponding to the predicted class.\n",
        "\n",
        "‚úÖ **Completion requirement**: Take any point from your test dataset, and compute a saliency map using `tf.GradientTape`. Check the weight to see if you can find anything to \"interpret\". **Note**: I am not evaluating how nice / good the explanation is, only the code."
      ],
      "metadata": {
        "id": "0i1Jr0mQ7lRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Take an element from your test set and compute the saliency map"
      ],
      "metadata": {
        "id": "WGeQDlEpJ-3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Check the saliency map to analyze the result. What can you say about the map?"
      ],
      "metadata": {
        "id": "o4nEAHpD6dlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3: Advanced saliency maps (1 point)\n",
        "\n",
        "> For this exercise, you can read [2] for an overview on the limits of vanilla saliency maps and a description of SmoothGrad.\n",
        "\n",
        "Saliency maps have several issues: most notably, they suffer from noise and they are not stable to small changes in the input or in the model (try running again the training and interpreting the same point). Many methods have been proposed to overcome this.\n",
        "\n",
        "**[SmoothGrad](https://arxiv.org/abs/1706.03825)**, for example, computes multiple saliency maps from noisy versions of the input:\n",
        "\n",
        "$$\n",
        "  \\text{SmoothGrad}(x) = \\frac{1}{n}\\sum_{i=1}^n S(x + \\varepsilon_i), \\;\\; \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2I)\n",
        "$$\n",
        "\n",
        "where $\\varepsilon$ is a vector of the same shape as $x$, whose values are sampled from a normal distribution with zero mean and small variance.\n",
        "\n",
        "üü© **Completion requirement**: Implement the SmoothGrad procedure for the same point. Has the explanation improved? Bonus points if you can avoid running a for-loop, and by calling the gradient operation a single time.\n"
      ],
      "metadata": {
        "id": "XXUhR5ZH9PKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Take an element from your test set and compute SmoothGrad. Check the results and compare with respect to the previous exercise."
      ],
      "metadata": {
        "id": "rJZBZUFA6POv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4: Global explanations (2 points)\n",
        "\n",
        "The previous exercises are examples of **local** explanations, where we try to interpret a single prediction of the network. Sometimes we are interested in **global** explanations, that try to find common patterns of behaviour. Suppose we have a dataset $\\mathcal{T} = \\left\\{x_i\\right\\}$ of examples, we can compute some approximate global measure of influence by averaging their saliency:\n",
        "\n",
        "$$\n",
        "\\text{GlobalSaliency} = \\frac{1}{n} \\sum_i S(x_i)\n",
        "$$\n",
        "\n",
        "To make this exercise more interesting, we will split it into 3 parts.\n",
        "\n",
        "**Exercise 4.1**: write a function to compute in parallel the saliency for multiple examples. Note that the resulting matrix $S$ will have shape $(n, d)$, where $n$ is the number of examples and $d$ the size of the input, which is the Jacobian of the network. Try to write the function by avoiding for-loops and multiple tapes, using the [proper tools from TensorFlow](https://www.tensorflow.org/guide/advanced_autodiff)."
      ],
      "metadata": {
        "id": "pIFUonMOY-Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the required function, possibly avoding for-loops."
      ],
      "metadata": {
        "id": "nJdQ6nbp-rIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4.2**: write a function to compute the global saliency and try to explain the results."
      ],
      "metadata": {
        "id": "As4lalRBcMHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the required function."
      ],
      "metadata": {
        "id": "O08JfYJQcS1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4.3**: note that a linear model $f(x) = w^\\top x + b$ is an example of an *intrinsically* interpretable  model, since the weights $w$ can be checked to analyze the global saliency of each feature (see [3])."
      ],
      "metadata": {
        "id": "D2j6pi3XcX86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Compare the results you obtained before with a simpler linear model."
      ],
      "metadata": {
        "id": "vjnDxBNicom1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional exercises and parting words\n",
        "\n",
        "> ‚ö† Explainability is a complex topic, with multiple issues arising from the over-abundance of techniques, their instability, etc. While an interesting research topic to pursue, never use blindly these techniques in high-stake applications!\n",
        "\n",
        "These exercises were just a brief and short introduction to the topic of explainability. Below you can find some additional exercises to tackle if you are interested. Remember that these are not part of your grade, but I am happy to provide feedback if they are of interest to you.\n",
        "\n",
        "1. There are dozens of possible variations on feature attribution methods, which may or may not provide better results (see [4] for a benchmarking and this nice [Distill blog post](https://distill.pub/2020/attribution-baselines/)). **[Integrated Gradients](https://arxiv.org/abs/1703.01365)** are an interesting example, where the saliency is integrated over a path ranging from an empty input to the true input. Try implementing integrated gradients.\n",
        "2. **Data attribution** methods are a different class of explanation methods, which try to predict what points in the dataset where most influential to a given prediction (e.g., a picture of a cat will be especially influential on similar pictures). One example of such methods is TracIn [5], which stores checkpoints of the model during training and evaluates the correlation of the gradients. Try to implement TracIn or any other metric of data influence.\n",
        "3. A recent line of research tries to use large language models (e.g., ChatGPT) to explain other models (e.g., see [Language models can explain neurons in language models](https://openai.com/research/language-models-can-explain-neurons-in-language-models)). If you have access to an LLM, you can try it! Take a specific neuron in the model, and collect the activation for multiple examples. Provide these activations to the LLM, and prompt it to provide a human-understandable explanation. What is the result?"
      ],
      "metadata": {
        "id": "Pp2K2VXGdAtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final checklist\n",
        "\n",
        "1. Carefully check all code. Insert comments when needed. Search for \"TODO\" to see if you forgot something.\n",
        "2. Run everything one final time. *Please do not send me notebooks with errors or cells that are not working.*\n",
        "3. Upload the completed notebook **before 10/11/2023 23:59** on the Google Classrom page."
      ],
      "metadata": {
        "id": "GIyU8c7lh4Ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bibliography\n",
        "\n",
        "[1] Simonyan, K., Vedaldi, A. and Zisserman, A., 2013. [Deep inside convolutional networks: Visualising image classification models and saliency maps](https://arxiv.org/abs/1312.6034). arXiv preprint arXiv:1312.6034.\n",
        "\n",
        "[2] Smilkov, D., Thorat, N., Kim, B., Vi√©gas, F. and Wattenberg, M., 2017. [SmoothGrad: removing noise by adding noise](https://arxiv.org/abs/1706.03825). arXiv preprint arXiv:1706.03825.\n",
        "\n",
        "[3] Rudin, C., 2019. [Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead](https://www.nature.com/articles/s42256-019-0048-x). Nature Machine Intelligence, 1(5), pp. 206-215.\n",
        "\n",
        "[4] Nguyen, G., Kim, D. and Nguyen, A., 2021. [The effectiveness of feature attribution methods and its correlation with automatic evaluation scores](https://proceedings.neurips.cc/paper/2021/hash/de043a5e421240eb846da8effe472ff1-Abstract.html). Advances in Neural Information Processing Systems, 34, pp.26422-26436.\n",
        "\n",
        "[5] Pruthi, G., Liu, F., Kale, S. and Sundararajan, M., 2020. [Estimating training data influence by tracing gradient descent](https://proceedings.neurips.cc/paper/2020/hash/e6385d39ec9394f2f3a354d9d2b88eec-Abstract.html). Advances in Neural Information Processing Systems, 33, pp. 19920-19930."
      ],
      "metadata": {
        "id": "YCfzjQOIe6CQ"
      }
    }
  ]
}